{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06bd08e2-9cd2-4737-99a6-5924dc442286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4810ca57-5e23-48de-b6d8-72160651bb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchExtended</th>\n",
       "      <th>Complete?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>K129270 Arbets- och metodbeskrivning ska minst...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19127</th>\n",
       "      <td>K111518 Dagvattenledning ska dimensioneras så ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>K162024 Knapp för lamptest ska finnas i anlägg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14371</th>\n",
       "      <td>K56326 Nätomkopplingsautomatik ska vara av typ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>K30863 Där BIS tillhandahåller uppgift om spår...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MatchExtended  Complete?\n",
       "2709   K129270 Arbets- och metodbeskrivning ska minst...        1.0\n",
       "19127  K111518 Dagvattenledning ska dimensioneras så ...        NaN\n",
       "4986   K162024 Knapp för lamptest ska finnas i anlägg...        NaN\n",
       "14371  K56326 Nätomkopplingsautomatik ska vara av typ...        NaN\n",
       "8566   K30863 Där BIS tillhandahåller uppgift om spår...        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"data/TRVInfra_all_only_requirements_202312.xlsx\", sheet_name=1, header=1, usecols=[3,4])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68353a53-6243-4083-9f05-e4fa4aaeb271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchExtended</th>\n",
       "      <th>Complete?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>Container för stationärt reservkraftaggregat ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20102</th>\n",
       "      <td>Ändring av en färgkod för färg i HMI ICS ska ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>VMS placerade över vägbana, där djupet på sky...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17016</th>\n",
       "      <td>Statustappningar från styrapparater i vägtraf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Navigeringsmeny i HMI ICS ska vara strukturer...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           MatchExtended  Complete?\n",
       "13164   Container för stationärt reservkraftaggregat ...        NaN\n",
       "20102   Ändring av en färgkod för färg i HMI ICS ska ...        NaN\n",
       "2057    VMS placerade över vägbana, där djupet på sky...        0.0\n",
       "17016   Statustappningar från styrapparater i vägtraf...        NaN\n",
       "2159    Navigeringsmeny i HMI ICS ska vara strukturer...        1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MatchExtended'] = df['MatchExtended'].str.replace(r'^K\\d{3,}', '', regex=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b20ee12b-116a-4ec7-92a7-baff556b4a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18316"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = df[df['Complete?'].isin([0.0, 1.0])]\n",
    "unlabeled = df[~df['Complete?'].isin([0.0, 1.0])]\n",
    "labeled.sample(5)\n",
    "len(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089ffb31-ddd1-463e-b8f2-5d0687d3f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = labeled.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c783608a-e7de-4cd6-ad2a-36eb505aaed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "grouped = labeled.groupby('Complete?')\n",
    "min_group_size = grouped.size().min()\n",
    "print(min_group_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d217ed6-e3a1-4a28-8bbb-5db838bc743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MatchExtended</th>\n",
       "      <th>Complete?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complete?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th>349</th>\n",
       "      <td>Produktdokumentation ska vara med minst följa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>Absolut, geodetisk, spårlägesmätning ska utfö...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>Vid trafikering på arbetsplats då spåret är o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>6.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Sidoslitaget (s) får inte överskrida: 1.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th>469</th>\n",
       "      <td>Känslighet för blockering i bromsprovare ska ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Bomrörelse vägbom öppningsbar bro, vägoperati...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>Dike ska utformas för att samla upp, infiltre...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>För ML-132 kV ställverk ska spänningsnivån va...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>Återgångsförhållandet ska vara 0,95 - 0,98.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    MatchExtended  Complete?\n",
       "Complete?                                                                   \n",
       "0.0       349    Produktdokumentation ska vara med minst följa...        0.0\n",
       "          2249   Absolut, geodetisk, spårlägesmätning ska utfö...        0.0\n",
       "          1898   Vid trafikering på arbetsplats då spåret är o...        0.0\n",
       "          654                                                  6.        0.0\n",
       "          2124           Sidoslitaget (s) får inte överskrida: 1.        0.0\n",
       "...                                                           ...        ...\n",
       "1.0       469    Känslighet för blockering i bromsprovare ska ...        1.0\n",
       "          1573   Bomrörelse vägbom öppningsbar bro, vägoperati...        1.0\n",
       "          1153   Dike ska utformas för att samla upp, infiltre...        1.0\n",
       "          2660   För ML-132 kV ställverk ska spänningsnivån va...        1.0\n",
       "          2958        Återgångsförhållandet ska vara 0,95 - 0,98.        1.0\n",
       "\n",
       "[958 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = grouped.apply(lambda x: x.sample(min_group_size))\n",
    "labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b52c01-fb89-41eb-92f0-6b3d693e3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = labeled['MatchExtended'].values\n",
    "labels = (labeled['Complete?'].values).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c093fab3-db97-42f5-8041-2bece84d19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f739c5-d034-43ed-82b8-b6435cd86a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:   Produktdokumentation ska vara med minst följande omfattning: a.\n",
      "Tokenized:  ['Produkt', '##dokument', '##ation', 'ska', 'vara', 'med', 'minst', 'följande', 'omfattning', ':', 'a', '.']\n",
      "Token IDs:  [14871, 33388, 223, 326, 358, 66, 1706, 3181, 7155, 126, 39, 7]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', sentences[0])\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22037c1-ad47-495e-b8cc-e6c7e4f7a20b",
   "metadata": {},
   "source": [
    "# Now we have prepared the data. Next we massage it so it can be ingested by BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dccf7e5a-e56e-4123-ad7e-6361a8071806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  151\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sent in sentences:\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24237ba5-a0b8-4e1e-b536-41e76a2cbfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mun/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:   Produktdokumentation ska vara med minst följande omfattning: a.\n",
      "Token IDs: tensor([    2, 14871, 33388,   223,   326,   358,    66,  1706,  3181,  7155,\n",
      "          126,    39,     7,     3,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent, \n",
    "        add_special_tokens = True, \n",
    "        max_length=max_len+1, \n",
    "        truncation=True,\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt')\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923e793-fd56-48a6-9a3a-4914c0286ff2",
   "metadata": {},
   "source": [
    "# Training, validation and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a5a646-1177-48ff-9c7c-1975029dbae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  862 learning samples\n",
      "  775 training samples\n",
      "   87 validation samples\n",
      "   96 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "learn_size = int(0.9 * len(dataset))\n",
    "train_size = int(0.9 * learn_size)\n",
    "val_size = learn_size - train_size\n",
    "test_size = len(dataset) - learn_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('{:>5,} learning samples'.format(learn_size))\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96966c45-e71e-4ea2-8a02-e2486c40ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    sampler = RandomSampler(train_dataset),\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    sampler = SequentialSampler(val_dataset),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc265cc9-9cbf-417c-9dd4-efc31d4fefb8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b01937e-e495-49ef-ba99-fd3d0bd282d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KB/bert-base-swedish-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KB/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'KB/bert-base-swedish-cased',\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea7696a-dd44-42c6-a4b8-7dbfca1177b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mun/.local/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=2e-5,\n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ce2329-8dd7-443f-b0c8-27ef4d6e87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00993d2-6db9-48ae-99ca-ef397ee7cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abce159c-47fd-4e26-981b-8204cdca1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "326f479a-2dd3-4d25-9246-0738f57cc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epoch took: 0:09:59\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "  Validation Loss: 0.13\n",
      "  Validation took: 0:00:26\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:10:25 (h:mm:ss)\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epoch took: 0:09:11\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.08\n",
      "  Validation took: 0:00:22\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:19:58 (h:mm:ss)\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epoch took: 0:11:29\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.98\n",
      "  Validation Loss: 0.12\n",
      "  Validation took: 0:00:27\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:31:54 (h:mm:ss)\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:10:21\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "  Validation Loss: 0.15\n",
      "  Validation took: 0:00:22\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:42:37 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 23\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            loss = output.loss\n",
    "            logits = output.logits\n",
    "        \n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd00f221-3249-402f-b5a0-7b46c9f13534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0:09:59</td>\n",
       "      <td>0:00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0:09:11</td>\n",
       "      <td>0:00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0:11:29</td>\n",
       "      <td>0:00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0:10:21</td>\n",
       "      <td>0:00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.29         0.13           0.95       0:09:59         0:00:26\n",
       "2               0.10         0.08           0.98       0:09:11         0:00:22\n",
       "3               0.06         0.12           0.98       0:11:29         0:00:27\n",
       "4               0.04         0.15           0.96       0:10:21         0:00:22"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f98cdca3-d043-4dc6-9ab1-104207e5fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizer_config.json',\n",
       " './special_tokens_map.json',\n",
       " './vocab.txt',\n",
       " './added_tokens.json',\n",
       " './tokenizer.json')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "output_dir = '.'\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "#torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a419a8be-f2ce-4eb5-9945-4b0c1c95b608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50325, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer.from_pretrained(output_dir)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30124954-1e4b-44f3-be7c-1fb0f509da8d",
   "metadata": {},
   "source": [
    "# Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "441bcb40-540c-4d07-89b0-5da9f9698294",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler = SequentialSampler(test_dataset),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "115f4616-df50-4542-b74d-91f166e20031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 96 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8642139b-eda3-4a3b-9da4-056fc657d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 51 of 96 (53.12%)\n"
     ]
    }
   ],
   "source": [
    "num_test_labels = len(test_dataset)\n",
    "num_positive_labels = 0\n",
    "\n",
    "for batch in test_dataset:\n",
    "    num_positive_labels += batch[2]\n",
    "\n",
    "print('Positive samples: %d of %d (%.2f%%)' % (num_positive_labels, num_test_labels, (num_positive_labels / num_test_labels * 100.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "393b265e-909c-495a-b06d-9b36580761d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "for i in range(len(true_labels)):\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "caa572a5-99e7-44fd-a8f4-105042a63369",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m ax \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(matthews_set))), y\u001b[38;5;241m=\u001b[39mmatthews_set, ci\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMCC Score per Batch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "82d3097f-b59c-494f-98e6-6225f7321e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 1.000\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "print('Total MCC: %.3f' % mcc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d84cc17d-7ed5-4d4e-9349-c7bcf0676c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "flat_pred = np.argmax(np.concatenate(predictions, axis=0), axis=1)\n",
    "flat_true = np.concatenate(true_labels, axis=0)\n",
    "accuracy = np.sum(flat_pred == flat_true) / len(flat_pred)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df0265-1410-4003-b686-546ce40e56db",
   "metadata": {},
   "source": [
    "# Prediction on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "75b7e601-06b5-4860-80f4-34b6444d4f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  321\n"
     ]
    }
   ],
   "source": [
    "sentences = unlabeled['MatchExtended'].values\n",
    "\n",
    "max_len = 0\n",
    "for sent in sentences:\n",
    "    if type(sent) == str:\n",
    "        input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "        max_len = max(max_len, len(input_ids))\n",
    "print('Max sentence length: ', max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bcc797a3-e5a2-47ea-b453-2df534dba796",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idsn = []\n",
    "attention_masksn = []\n",
    "\n",
    "for sent in sentences[:100]:\n",
    "    if type(sent) == str:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent, \n",
    "            add_special_tokens = True, \n",
    "            max_length=max_len+1, \n",
    "            truncation=True,\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt')\n",
    "        input_idsn.append(encoded_dict['input_ids'])\n",
    "        attention_masksn.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_idsn, dim=0)\n",
    "attention_masks = torch.cat(attention_masksn, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "037820d7-f40e-4797-ba6c-e81dd73f63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks)\n",
    "\n",
    "unlabeled_dataloader = DataLoader(\n",
    "    dataset,\n",
    "    sampler = SequentialSampler(dataset),\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1ff6d6a3-cdce-4228-97b3-75515f7c84a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for batch in unlabeled_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  #label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  #true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "178bce30-1a2f-470c-a835-fb2261b0be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Vid montage i vinklar, utifrån rätlinje, ska spännkraft i tråd verka på stolpe, se figur K7.', 1), (' Projektorganisationen ska vara samordnande för arbetsprocessen enligt {Bilaga 1 Arbetsprocess integration styrapparat till ÖTS}.', 1), (' Lysande VMS får inte vara med frontglas/frontskärm.', 1), (' Genomföringar och anslutningar ska vara utformade så att två stycken 95 mm² 3-fas kablar kan anslutas.', 1), (' Kontakt i motorkrets ska kunna sluta och bryta ström hos fastbromsad motor.', 1), (' Toleranser ska uppfylla toleransklass 1 enligt SS-EN 13670:2009 - Betongkonstruktioner - Utförande 5.', 0), (' Bedömning av lämplighet som teknisk granskare ska göras av beställare baserande på underlag som lämnas av sökandes organisation.', 1), (' Fiberenheter i Trafikverkets optiska spridningsnät får endast skarvas mot pigtails eller fan-outs i ODF-enheter.', 1), (' För körfältsignaler MCS (TM), omställbara vägmärken (MV), i grafiska användargränssnitt, ska symboler för hastighet finnas med och utan röd ring för varje hastighet.', 1), (' Alla dragbrunnar/kabelbrunnar ska vara med fotodokumentation bestående av digitala fotografier tagna i anslutning till att lock läggs på dragbrunnar.', 1), (' Före och efter mätning på fiber i Trafikverkets optokabelanläggningar ska samtliga kontakter på mätinstrumentens mätkablar vara försedda med damm- och stötskydd.', 1), (' Kontaktledningsanläggning ska vara projekterad och byggd enligt TRVINFRA-00153 Elkraftanläggning Kontaktledning Kontaktledningssystem Projektering.', 1), (' Efter skarvning av fiber i Trafikverkets optokabelanläggningar ska skarvhylsor omedelbart anbringas på fiberskarvarna.', 1), (' Elektrisk utrustning som kraftförsörjs av Trafikverkets hjälpkraft ska klara industriklass 3 enligt SS-EN 61000-2-4 Elektromagnetisk kompatibilitet (EMC) - Del 2-4: Miljöbetingelser - Kompatibilitetsnivåer för lågfrekventa ledningsbundna störningar i industrimiljö.', 1), (' I ärende för kontroll ska följande uppgifter anges: \\uf0b7 Trafikverkets projektnummer och projektnamn \\uf0b7 Trafikverkets konstruktionsnamn och konstruktionsnummer på den geokonstruktion som avses \\uf0b7 vilka dokument och versioner av dessa som avses \\uf0b7 länk till lagringsplats för handlingar som lagts in i databas \\uf0b7 vilken typ av kontroll som avses \\uf0b7 det av handling upprättande företagets namn \\uf0b7 datering \\uf0b7 daterad underskrift \\uf0b7 kontaktuppgift för Trafikverkets projektledare \\uf0b7 kontaktuppgift för Trafikverkets kontraktspart \\uf0b7 kontaktuppgift för Trafikverkets teknikstöd för geoteknik \\uf0b7 kontaktuppgift för det av handling upprättande företagets uppdragsledare K99789 Handling i ärende för kontroll ska vara kvalitetssäkrad, komplett och färdig.', 1), (' Vid kontroll av räl och rälkomponent som ska återanvändas ska alla skarvar märkas med vit färg, detta inkluderar: 1.', 0), (' Avvattning ska ordnas med beaktande av omgivningskrav avseende vattenverksamhet.', 1), (' Servicedatorn ska vara utförd så att den kan användas för konfigurering, programunderhåll, programändring, felsökning och programnedladdningar av apparater i stationskontrollsystemet som exempelvis reläskydd, styrsystem.', 1), (' Order om funktionsläge från centralt system till objekt i lokal styrutrustning får inte accepteras när manöverläge är Avställd.', 1), (' Utlösningsimpulser från brytarfelsskydd ska ha en varaktighet på minst 500 ms.', 1), (' Flertågsdisplayer på mellanplattformar på järnvägsstationer med planskild plattformsförbindelse ska vara riktade mot plattformsentrén.', 1), (' Beräkning av spänningar i betongöverbyggnad ska utföras enligt CBI rapport 2:90.', 1), (' Säkerhetsutrustning ska innefatta objekt enligt tabell 1.', 1), (' Varje slutsvetsskarv ska dokumenteras, se avsnitt 7.', 1), (' Leverantörs föreskrifter och rekommendationer för utrustning som används vid neutralisering ska alltid följas.', 1), (' Dörrar av stål ska vara målade i kulör ljusgrå enligt tillverkarens standard.', 1), (' Den transportör som anlitas i samband med bortskaffande av kabel som har avlägsnats ur Trafikverkets kabelanläggningar ska ha erforderligt tillstånd alternativt vara anmäld hos länsstyrelsen i enlighet med Avfallsförordningen.', 1), (' Fundament som inte står i skydd av vägräcke eller dylikt ska placeras så att inte någon del av fundamentets överyta blir belägen högre än 0,1 m över färdig mark.', 1), (' Kontaktledningsfundament ska vara märkt med 1.', 0), (' Skåp ska vara utfört för trefasig strömmätning.', 1), (' Utspetsning ska utföras när olika tjällyftning kan förväntas längs väglinjen.', 1), (' Plastbelagd grind får inte finnas inom kontaktledningsområde enligt mått angivna i TDOK 2014:0416 Jordning och skärmning i Trafikverkets anläggningar.', 1), (' Underspänningsskydd ska vara försedda med minst en startutgång.', 1), (' Apparatskåp i öppningsbar bro, vägoperativ miljö, ska vara enligt {TRVINFRA-00250 Krav Apparatskåp vägoperativ miljö} med följande förändringar: a.', 0), (' Varje FOMUL ska beskrivas med minst två mätpunkter, med undantag för kontaktledningstråd som beskrivs med en enda mätpunkt.', 1), (' Längsgående vägmarkeringar ska uppfylla krav på funktion angivna i Tabell 9-3, beteckningar och enheter enligt SS-EN 1436.', 1), (' I samband med terminering av signalsäkerhetskretsar ska skruvplintar av typen knivfrånskiljarplint med Trafikverkets artikelnummer 5671264 användas för avslutning av kommunikationskabel TRV-ECLALPLE i signalskåp, signalkurar, kiosker och teknikhus.', 1), (' Signaler i integrationsgränssnitt RSMP för kommunikation med UMS ska vara definierade i en signalutbyteslista SXL enligt {TRVINFRA-00256 RSMP vägoperativ miljö}.', 1), (' Slänter och koner ska vara fria från buskar och sly, med en diameter som är mindre än 0,10 m, och som är högre än 0,5 m över markytan.', 1), (' Funktionsspecifikation ska vara med redovisning av driftläge vid felaktiga driftfall för att säkerställa att systemet inte riskerar att inta driftläge som kan vålla fara eller skada då eventuella fel inträffar.', 1), (' Metod för installation av fundament i bankropp ska vara godkänd av Trafikverket.', 1), (' Belysning inomhus ska var utfört med LED belysning.', 1), (' Utrustningar ska ha erforderlig transient- och spänningstålighet för säkerställande av god funktion i den aktuella miljön.', 1), (' Bromsprovare ska vara med avgiven signal till operatör då beräkningen är klar.', 1), (' Tilläggsskylt för avståndsangivelse ska kompletteras med tilläggsskylt för avståndsangivelse med låssymbol när avstånd till en låst grind är kortare än till stängselavslut.', 1), (' Tillsyn, efter arbeten, av skarvspår vid hög temperatur ska utföras enligt avsnitt 7.', 1), (' Funktionen av brandlarmssystem i personalutrymmen och verkstad ska vara utförd så att brandindikering i två detektorer utlöser brandlarm.', 1), (' LED-handledare ska ha kabelkanal för erforderliga kablar till system för allmän- /utrymningsbelysning, säkerhetsskyltar samt knappar, se Figur 5.', 1), (' Den person som ansvarar för förläggning av kablar, optorör och dukter i Trafikverkets kabelanläggningar ska även ansvara för att personalen förstår vikten av att kablarna, optorören och dukterna hanteras varsamt.', 1), (' Ren- och viltstängsel ska vara av typen rutnät.', 1), (' På bangårdar och perronger där personer rör sig samt på platser där ett stag kan utgöra hinder för andra anläggningsdelar ska sträva monteras.', 1), (' Anslutningsklämmorna ska vara utförda för ledare med upp till 6 mm2 area.', 1), (' Den utrustning som är placerad utomhus och kan skadas av fåglar eller andra djur ska vara skyddad på ett effektivt sätt.', 1), (' Munstycket är en högkvalitetsdetalj med mycket små toleranser och ska hanteras mycket varsamt, det får inte tappas i ballasten.', 1), (' Kontrollgrop vid trafikkontrollplats ska vara dimensionerad för kontroll av axlar, boggi och hela fordonskonstruktioner på alla förekommande fordon som är avsedda för bruk på det allmänna vägnätet.', 1), (' En befintlig höjande hastighetstavla (ger ett högre hastighetsbesked än tidigare gällande) som ligger strax före hastighetsnedsättningens början ska täckas över om 1.', 0), (' Sektionsisolator får inte vara placerad närmare, utliggare med tillsatsrör än 10 meter, utliggare utan tillsatsrör 6 meter.', 1), (' Signalsäkerhetsgranskare ska ansvara med relevant behörighet för att säkerhetsgranska de projekteringar som eventuellt utförs under ibruktagandebesiktningen.', 1), (' Figur 11-4.', 0), (' Jordens halt av stora block (> 630 mm) ska anges om den bedöms överstiga 1 viktprocent.', 1), (' Om rälsbrott inträffat i plankorsning och reparation eller tillfällig reparation inte kan genomföras omgående får tåg passera om punkterna 1–9 uppfylls: 1.', 0), (' Märkbrickor ska placeras enligt följande.', 0), (' Tillslagsblockad för brytare ska vara aktiverad tills totalstopp är återställt.', 1), (' Kabel i växel- eller spårspärrdriv ska vara förankrad i drivets kabelförskruvning och kabeltrådarna ska vara 1.', 0), (' Bygghandling ska granskas med avseende att styrande tekniska regelverk följts (teknisk granskning).', 1), (' Anläggningsdel, apparat eller koppling som tillkommer ska markeras på ändringsversionen av ett signaldokument med grön färg.', 1), (' Lokala styrutrustningar ska vara med funktion för att automatiskt synkronisera datum och tid mot av Beställaren anvisad NTP-server.', 1), (' Nybyggnadstoleranser för spårvidds- och styrviddsmått ska vara enligt någon av punkterna 1–11 för: 1.', 0), (' Stängsel av stålnätspaneler ska utföras så att topografiska eller andra förhållanden, som t.', 0), (' Märkskyltar för MCS-portaler ska vara 450 mm breda.', 1), (' Vägmärken, inklusive bärare och fundament, ska uppfylla krav på bärförmåga, stadga och beständighet under de förutsättningar som råder på platsen.', 1), (' Positionsljus på öppningsbar bro, vägoperativ miljö, ska vara styrda av lokalt styrsystem (PLC).', 1), (' Fästet för kabelavslutet ska klara lasten från kabelavslutet.', 1), (' När NIS-skydd används för ökad känslighet vid jordfel ska NIS-skydd vara monterat i kapsling.', 1), (' Montageritningar VVS ska vara upprättade för utrustning ingående i VVS-system i teknikhus/driftutrymme.', 1), (' För situation som kan orsaka annan skada ska återkomsttid lägst 50 år väljas.', 1), (' Beskedet i huvudljussignal ska överensstämma med ATC-beskedet enligt tabell nedan.', 1), (' Om kran har använts som provtagningsställe ska kranens placering på transformator vara angiven i provtagningsunderlaget.', 1), (' Placering av lokalställare ska vara på den plats varifrån vägskyddsanläggningen ska manövreras och där vägtrafiken i plankorsningen kan överblickas.', 1), (' Gemensamt provningssteg OAT ska påbörjas enligt {K211625}.', 1), (' Om korsande kabel, korsande kabelkanalisation och/eller korsande ledningar upptäcks innan förplöjning inför förläggning av kablar, optorör och dukter i Trafikverkets kabelanläggningar påbörjas ska detta noteras i mätboken och/eller på skarv- och kabellägesplanen.', 1), (' Flödet från ett lokalt inläckningsställe ska vara mindre än 1 droppe/minut över \\uf0b7 kontaktledningssystem och räler \\uf0b7 plattformar \\uf0b7 installationer för nödsituationer som t.', 0), (' Rälskarvar på höger och vänster räl ska placeras i samma slipersfack.', 1), (' Sektionsutliggare sidomonterad i enkel- och dubbelspårstunnel ska vara utformade enligt typritning i tabell 12.', 1), (' Tvärgående fel i rälhuvud i korsningsspets/spetsräl, ska klassificeras som grupp 2-fel om punkt nedan uppfylls: 1.', 0), (' Vid dimensionering ska förväntade deformationer beaktas så att förutsatt samverkan med omgivande jord och berg säkerställs.', 1), (' LED-enheter i trafiksignallyktor i släckt läge ska vara med sådan impedans att eventuellt inducerad spänning på matningsledningen kan avledas.', 1), (' Vid bestämning av härledda värden ska de uppmätta värdena utvärderas och korrigeras utifrån den beräkningsmodell som egenskaperna ska ingå i.', 1), (' Radarenheten ska med vinklingsbara standardfästen kunna monteras på både vägg, hörn och stolpe (diameter 80-150mm).', 1), (' Villkor för fordon där längdmått överskrider normalfordons (18 m mellan boggicentra och 3 m från boggicentra till vagnsände) ska beräknas från fall till fall.', 1), (' För bro med väg, gång- och cykeltrafik ska krav enligt \"Vägars och gators utformning\" (Trafikverket) uppfyllas.', 1), (' Kapslingen ska vara utförd i rostfritt stål eller målad aluminium.', 1), (' Fågelavvisare ska vara monterad på balk, vindförband och konsoler enligt typritning 800 167 där det finns bärlina över balkbrygga.', 1), (' \"Start pågår\" ska indikeras via FA stift 4.', 1), (' Funktion vid planerat och oplanerat nätavbrott samt återgång till nätdrift ska redovisas.', 1), (' Med refsp ska avses det spår som fordon färdas på.', 1), (' Renslucka som sitter i isolerad ventilationskanal ska vara utförd i minst samma isoleringsklass som kanalen.', 1), (' Säkringsplatser för utgående grupper ska vara utformade så att reservkapacitet med minst 30 % lediga grupper finns.', 1), (' Detaljritning ska vara i skala 1:10, 1:20 eller 1:50 om annan skala inte specificeras i projektet.', 1), (' Kalibrering av mätvärdesomvandlare ska vara utförd med frikopplade in- och utgångar.', 1)]\n"
     ]
    }
   ],
   "source": [
    "flat_pred = np.argmax(np.concatenate(predictions, axis=0), axis=1)\n",
    "r = zip(sentences[:100], flat_pred)\n",
    "print(list(r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
